{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.2 (main, Feb  7 2025, 09:17:17) [Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "['/usr/local/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python313.zip', '/usr/local/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13', '/usr/local/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload', '', '/Users/gon9a/workspace/rag/rag_tutorial_lc/.venv/lib/python3.13/site-packages', '/Users/gon9a/workspace/rag/rag_tutorial_lc']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envから環境変数を読み込む\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 'OPENAI_API_KEY' を設定してください。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "。\n",
      "\n",
      "私は、山������と��します。��在、大学の����学部に通っており、主に国������学を����しています。大学では、国��情��やグロー��ルビジ��スについて学��ことで、��界の�����な問��や����の����みを理解し、将来は国��的な����を持ったビジ��スパー��ンとして活���したいと考えています。����は、��行やスポー������で、国内外を問わ�������な場所を��れることで、��文化や言��に��れることができるのが��し��です。また、ビジ��スの��界だけでなく、社会や�����の問��にも\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-3.5-turbo-instruct\" ,#\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "# 3.5-turbo-instruct\n",
    "output = llm.invoke(\"自己紹介をしてください\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4o-mini チャット形式のやり取りを入力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='もちろんです！どのようなコードを作成したいか、具体的な要件や目的を教えていただけますか？例えば、データ処理、Webアプリケーション、ゲーム、または何か特定のアルゴリズムなど、具体的なアイデアがあればお知らせください。それに基づいてコードを提供します。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 30, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None} id='run-dfebf7c6-668e-43da-b837-c8b75aa8ddd6-0' usage_metadata={'input_tokens': 30, 'output_tokens': 82, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "# 4o-mini チャット形式のやり取りを入力する\n",
    "messages = [\n",
    "    SystemMessage(content=\"あなたはプロのコーディング講師です。\"),\n",
    "    HumanMessage(content=\"pythonのコードを書いてください。\")\n",
    "]\n",
    "output = llm.invoke(messages)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "もちろんです！どのようなコードを必要としていますか？具体的な要件や機能があれば教えてください。たとえば、データ処理、ウェブスクレイピング、ゲーム、GUIアプリケーションなど、さまざまなジャンルがあります。"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "# 4o-mini チャット形式のやり取りを入力する\n",
    "messages = [\n",
    "    SystemMessage(content=\"あなたはプロのコーディング講師です。\"),\n",
    "    HumanMessage(content=\"pythonのコードを書いてください。\")\n",
    "]\n",
    "output = llm.invoke(messages)\n",
    "\n",
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt テンプレート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='あなたはプロのコーディング講師です。', additional_kwargs={}, response_metadata={}), HumanMessage(content='pythonのコードを書いてください。', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたはプロのコーディング講師です。\"),\n",
    "    (\"human\", \"{language}のコードを書いてください。\")\n",
    "])\n",
    "\n",
    "prompt_value = prompt.invoke({\"language\": \"python\"})\n",
    "\n",
    "print(prompt_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessagePlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='あなたはプロのコーディング講師です。', additional_kwargs={}, response_metadata={}), HumanMessage(content='pythonのコードを書いてください。', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたはプロのコーディング講師です。\"),\n",
    "    MessagesPlaceholder(\"chat_hostory\", optional=True),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt_value = prompt.invoke({\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(content=\"あなたはpythonのコードのプロです！！。\"),\n",
    "        AIMessage(content=\"いやぁ、今日は風が強いですねぇ。\")\n",
    "    ],\n",
    "    \"input\": \"pythonのコードを書いてください。\"\n",
    "})\n",
    "\n",
    "print(prompt_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"食材のリスト\")\n",
    "    steps: list[str] = Field(description=\"作り方のリスト\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"食材のリスト\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"作り方のリスト\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたはプロのコーディング講師です。\"),\n",
    "    (\"human\", \"{language}のコードを書いてください。\")\n",
    "])\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### format_instructionsを使ったChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ユーザが入力した料理のレシピを考えてください。\\n\\n以下のフォーマットで出力してください。\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"ingredients\": {\"description\": \"食材のリスト\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"作り方のリスト\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\\n```', additional_kwargs={}, response_metadata={}), HumanMessage(content='カレー', additional_kwargs={}, response_metadata={})]\n",
      "role: system\n",
      "ユーザが入力した料理のレシピを考えてください。\n",
      "\n",
      "以下のフォーマットで出力してください。\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"食材のリスト\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"作り方のリスト\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n",
      "role: human\n",
      "カレー\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ユーザが入力した料理のレシピを考えてください。\\n\\n\"\n",
    "     \"以下のフォーマットで出力してください。\\n\\n\"\n",
    "     \"{format_instructions}\"),\n",
    "    (\"human\", \"{dish}\")\n",
    "])\n",
    "\n",
    "prompt_with_format_instructions = prompt.partial( # patrialはパラメータを固定して新しいpromptを作る\n",
    "    format_instructions = format_instructions\n",
    "    )\n",
    "\n",
    "prompt_value = prompt_with_format_instructions_value = prompt_with_format_instructions.invoke({\"dish\": \"カレー\"})\n",
    "print(prompt_value)\n",
    "print(\"role: system\")\n",
    "print(prompt_value.messages[0].content)\n",
    "print(\"role: human\")\n",
    "print(prompt_value.messages[1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"ingredients\": [\\n    \"鶏肉 500g\",\\n    \"玉ねぎ 2個\",\\n    \"にんじん 1本\",\\n    \"じゃがいも 2個\",\\n    \"カレールー 1箱\",\\n    \"水 600ml\",\\n    \"サラダ油 大さじ2\",\\n    \"塩 少々\",\\n    \"こしょう 少々\"\\n  ],\\n  \"steps\": [\\n    \"鶏肉を一口大に切り、塩とこしょうを振って下味をつける。\",\\n    \"玉ねぎを薄切り、にんじんとじゃがいもを一口大に切る。\",\\n    \"鍋にサラダ油を熱し、玉ねぎを炒めて透明感が出るまで炒める。\",\\n    \"鶏肉を加えて表面が白くなるまで炒める。\",\\n    \"にんじんとじゃがいもを加え、全体を混ぜながら炒める。\",\\n    \"水を加え、煮立ったらアクを取り除く。\",\\n    \"中火で約15分煮込み、野菜が柔らかくなったらカレールーを加える。\",\\n    \"ルーが溶けるまでかき混ぜ、さらに5分ほど煮込む。\",\\n    \"味を見て、必要であれば塩で調整する。\",\\n    \"ご飯と一緒に盛り付けて、完成。\"\\n  ]\\n}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 338, 'prompt_tokens': 239, 'total_tokens': 577, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-23aedf54-ad11-44bc-a4e3-6e301eea9957-0' usage_metadata={'input_tokens': 239, 'output_tokens': 338, 'total_tokens': 577, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "ai_response = model.invoke(prompt_value)\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ingredients\": [\n",
      "    \"鶏肉 500g\",\n",
      "    \"玉ねぎ 2個\",\n",
      "    \"にんじん 1本\",\n",
      "    \"じゃがいも 2個\",\n",
      "    \"カレールー 1箱\",\n",
      "    \"水 600ml\",\n",
      "    \"サラダ油 大さじ2\",\n",
      "    \"塩 少々\",\n",
      "    \"こしょう 少々\"\n",
      "  ],\n",
      "  \"steps\": [\n",
      "    \"鶏肉を一口大に切り、塩とこしょうを振って下味をつける。\",\n",
      "    \"玉ねぎを薄切り、にんじんとじゃがいもを一口大に切る。\",\n",
      "    \"鍋にサラダ油を熱し、玉ねぎを炒めて透明感が出るまで炒める。\",\n",
      "    \"鶏肉を加えて表面が白くなるまで炒める。\",\n",
      "    \"にんじんとじゃがいもを加え、全体を混ぜながら炒める。\",\n",
      "    \"水を加え、煮立ったらアクを取り除く。\",\n",
      "    \"中火で約15分煮込み、野菜が柔らかくなったらカレールーを加える。\",\n",
      "    \"ルーが溶けるまでかき混ぜ、さらに5分ほど煮込む。\",\n",
      "    \"味を見て、必要であれば塩で調整する。\",\n",
      "    \"ご飯と一緒に盛り付けて、完成。\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(ai_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingredients=['鶏肉 500g', '玉ねぎ 2個', 'にんじん 1本', 'じゃがいも 2個', 'カレールー 1箱', '水 600ml', 'サラダ油 大さじ2', '塩 少々', 'こしょう 少々'] steps=['鶏肉を一口大に切り、塩とこしょうを振って下味をつける。', '玉ねぎを薄切り、にんじんとじゃがいもを一口大に切る。', '鍋にサラダ油を熱し、玉ねぎを炒めて透明感が出るまで炒める。', '鶏肉を加えて表面が白くなるまで炒める。', 'にんじんとじゃがいもを加え、全体を混ぜながら炒める。', '水を加え、煮立ったらアクを取り除く。', '中火で約15分煮込み、野菜が柔らかくなったらカレールーを加える。', 'ルーが溶けるまでかき混ぜ、さらに5分ほど煮込む。', '味を見て、必要であれば塩で調整する。', 'ご飯と一緒に盛り付けて、完成。']\n",
      "<class '__main__.Recipe'>\n"
     ]
    }
   ],
   "source": [
    "recipe = output_parser.invoke(ai_response)\n",
    "print(recipe)\n",
    "print(type(recipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、私はカレーを作りたいと思います。ブンブンジャー！\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "ai_message = AIMessage(content=\"こんにちは、私はカレーを作りたいと思います。ブンブンジャー！\")\n",
    "\n",
    "ai_message_str = output_parser.invoke(ai_message)\n",
    "print(ai_message_str)\n",
    "print(type(ai_message_str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
